{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the using package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import monpa\n",
    "import random\n",
    "import pickle\n",
    "import torch.nn.init as weight_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.GRU):\n",
    "        nn.init.orthogonal_(m.all_weights)\n",
    "        nn.init.orthogonal_(m.all_bias)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture of the Designed Model using only Bi-GRU \n",
    "<img src=\"https://i.imgur.com/wOizgXZ.png\" width = \"300\" height = \"200\" alt=\"design_model\" align=center />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bi_GRU_Model (nn.Module):\n",
    "    def __init__(self, total_tag, embeding_size, gru_hidden,gru_layer, output_size):\n",
    "        super(Bi_GRU_Model, self).__init__()\n",
    "        self.total_tag = total_tag\n",
    "        self.embeding_size = embeding_size\n",
    "        self.gru_hidden = gru_hidden\n",
    "        self.gru_layer = gru_layer\n",
    "        self.output_size = output_size\n",
    "        self.Embeding = nn.Embedding(self.total_tag, self.embeding_size)\n",
    "        self.GRU = nn.GRU(self.embeding_size , self.gru_hidden, self.gru_layer, bidirectional= True)\n",
    "        weight_init.orthogonal_(self.GRU.weight_ih_l0)\n",
    "        weight_init.orthogonal_(self.GRU.weight_hh_l0)\n",
    "        # use zero init for GRU layer0 bias\n",
    "        #self.GRU.bias_ih_l0.zero_()\n",
    "        #self.GRU.bias_hh_l0.zero_()\n",
    "        \n",
    "        # batch size is  set to 1 , output_size is set to 2\n",
    "        self.linear = nn.Linear( self.gru_hidden*2 , self.output_size )\n",
    "        \n",
    "    def forward(self, input_data):  \n",
    "        embed_res = self.Embeding (input_data)\n",
    "        #print ('Embedding :::: ' , embed_res.size())\n",
    "        # let the input dimension be the (L , N , M) and the get the output with the dimension (L , N , H)\n",
    "        gru_res, _ = self.GRU(embed_res.unsqueeze(1))\n",
    "        #print (\"GRU :::: \", gru_res.size())\n",
    "        linear_res = self.linear(gru_res[-1])\n",
    "        final_res = F.log_softmax(linear_res)\n",
    "        #print ('final res :::: ' , final_res)\n",
    "        return final_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_Model_with_only_gru ::: \n",
      " Bi_GRU_Model(\n",
      "  (Embeding): Embedding(16, 8)\n",
      "  (GRU): GRU(8, 6, num_layers=4, bidirectional=True)\n",
      "  (linear): Linear(in_features=12, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "model_v1 = Bi_GRU_Model(total_tag=16, embeding_size=8, gru_hidden= 6 , gru_layer=4, output_size=7 )\n",
    "#model_v1.GRU.apply(weights_init)\n",
    "test_vec = torch.LongTensor([1,2,3,4,5,6,7])\n",
    "model_v1(test_vec)\n",
    "print ('V1_Model_with_only_gru ::: \\n', model_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "* 將positive_data和negative_data載入存入List\n",
    "* 將monpa的tags載入dictionary\n",
    "* 將sentence 的 words 轉成詞性\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size :  7070\n",
      "training data target size :  7070\n"
     ]
    }
   ],
   "source": [
    "training_data_sentence_list = list()\n",
    "training_data_tag_list = list()\n",
    "training_target_sentence_list = list()\n",
    "dict_idx2tag = dict()\n",
    "dict_tag2idx = dict()\n",
    "'''\n",
    "with open ('../CJX_Train_Test_Data/try_train_p_v2.txt', 'r', encoding = 'utf-8') as rf:\n",
    "    for pos_s in rf.readlines():\n",
    "        training_data_sentence_list.append(pos_s.strip('\\n').strip(',').strip('，').strip('《').strip('》').strip('【').strip('】').strip('、').strip('、').strip('-'))\n",
    "        training_target_sentence_list.append(1)\n",
    "with open ('../CJX_Train_Test_Data/try_train_n.txt', 'r', encoding = 'utf-8') as rf:\n",
    "    for pos_s in rf.readlines():\n",
    "        training_data_sentence_list.append(pos_s.strip('\\n').strip(',').strip('，').strip('《').strip('》').strip('【').strip('】').strip('、').strip('-'))\n",
    "        training_target_sentence_list.append(0)\n",
    "tmp_cnt = 0\n",
    "# Change the words to tags, because we need to use the sequential tags for training.\n",
    "for sentence in training_data_sentence_list:\n",
    "    tmp_cnt += 1\n",
    "    #print (tmp_cnt)\n",
    "    tmp = monpa.pseg(sentence)\n",
    "    tmp_list = list()\n",
    "    for item in tmp:\n",
    "        tmp_list.append(item[1])\n",
    "    training_data_tag_list.append(tmp_list)\n",
    "    \n",
    "print (len(training_data_tag_list))\n",
    "'''\n",
    "\n",
    "# Read both the postive data and negative data\n",
    "with open ('../CJX_Train_Test_Data/positive_data.txt', 'r', encoding = 'utf-8') as rf:\n",
    "    for pos_s in rf.readlines():\n",
    "        training_data_sentence_list.append(pos_s.strip('\\n').strip(',').strip('，').strip('《').strip('》').strip('【').strip('】').strip('、').strip('、').strip('-'))\n",
    "        training_target_sentence_list.append(1)\n",
    "with open ('../CJX_Train_Test_Data/positive_data.txt', 'r', encoding = 'utf-8') as rf:\n",
    "    for pos_s in rf.readlines():\n",
    "        training_data_sentence_list.append(pos_s.strip('\\n').strip(',').strip('，').strip('《').strip('》').strip('【').strip('】').strip('、').strip('-'))\n",
    "        training_target_sentence_list.append(0)\n",
    "        \n",
    "print ('training data size : ',len(training_data_sentence_list))\n",
    "print ('training data target size : ',len(training_target_sentence_list))\n",
    "tmp_cnt = 0\n",
    "# Change the words to tags, because we need to use the sequential tags for training.\n",
    "for sentence in training_data_sentence_list:\n",
    "    tmp_cnt += 1\n",
    "    #print (tmp_cnt)\n",
    "    tmp = monpa.pseg(sentence)\n",
    "    tmp_list = list()\n",
    "    for item in tmp:\n",
    "        tmp_list.append(item[1])\n",
    "    training_data_tag_list.append(tmp_list)\n",
    "    \n",
    "print (len(training_data_tag_list))\n",
    "\n",
    "# Read the tags of the monpa\n",
    "with open ('./monpa_tag.txt' , 'r' , encoding = 'utf-8') as rf:\n",
    "    cnt = 0\n",
    "    for tag in rf.readlines():\n",
    "        dict_idx2tag[cnt] = tag.strip('\\n')\n",
    "        dict_tag2idx[tag.strip('\\n')] = cnt\n",
    "        cnt += 1  \n",
    "\n",
    "print ('The dictionary of idxs 2 tags : ', dict_idx2tag)\n",
    "print ('The dictionary of tags 2 idxs : ' , dict_tag2idx)\n",
    "\n",
    "shuffle_zip = list(zip(training_data_tag_list, training_target_sentence_list))\n",
    "random.shuffle(shuffle_zip)\n",
    "training_data_tag_list[:], training_target_sentence_list[:] = zip(*shuffle_zip)\n",
    "print (training_data_tag_list, training_target_sentence_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('../pickle/training_tags.pkl', 'wb')\n",
    "pickle.dump(training_data_tag_list, f)\n",
    "f.close()\n",
    "f = open ('../pickle/target.pkl', 'wb')\n",
    "pickle.dump(training_target_sentence_list, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('../pickle/training_tags.pkl', 'rb')\n",
    "a = pickle.load( f)\n",
    "f.close()\n",
    "f = open ('../pickle/target.pkl', 'rb')\n",
    "b = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_idx2tag = dict()\n",
    "dict_tag2idx = dict()\n",
    "with open ('./monpa_tag.txt' , 'r' , encoding = 'utf-8') as rf:\n",
    "    cnt = 0\n",
    "    for tag in rf.readlines():\n",
    "        dict_idx2tag[cnt] = tag.strip('\\n')\n",
    "        dict_tag2idx[tag.strip('\\n')] = cnt\n",
    "        cnt += 1  \n",
    "#training_data_tag_list = a\n",
    "#training_target_sentence_list = b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamters_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_v1 = 100\n",
    "learning_rate_v1 = 0.01\n",
    "input_size_v1 = len(dict_idx2tag.keys())\n",
    "gru_hidden_size_v1 = 10\n",
    "embedding_size_v1 = 32\n",
    "output_size_v1 = 2\n",
    "gru_layer_v1 = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義訓練function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_v1():\n",
    "    model_v1 = Bi_GRU_Model(total_tag=input_size_v1, \n",
    "                            embeding_size = embedding_size_v1,\n",
    "                            gru_hidden=gru_hidden_size_v1,\n",
    "                            output_size=output_size_v1,\n",
    "                            gru_layer = gru_layer_v1)\n",
    "    #model_v1.apply(weights_init)\n",
    "    optimizer_v1 = torch.optim.SGD(model_v1.parameters(), lr=learning_rate_v1)\n",
    "    loss_function_v1 = nn.NLLLoss()\n",
    "    \n",
    "    for epoch in range(epoch_v1):\n",
    "        sub_epoch = 0\n",
    "        total_loss = 0\n",
    "        #print (len(training_data_tag_list))\n",
    "        for seq_tag_idx in range(len(training_data_tag_list)):\n",
    "            sub_epoch += 1\n",
    "            input_data = torch.LongTensor([dict_tag2idx[t] for t in training_data_tag_list[seq_tag_idx]])\n",
    "            target_data = torch.LongTensor([training_target_sentence_list[seq_tag_idx]])\n",
    "            out = model_v1(input_data)\n",
    "            loss = loss_function_v1(out, target_data)\n",
    "            total_loss += loss.item()\n",
    "            optimizer_v1.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_v1.step()\n",
    "            '''\n",
    "            if sub_epoch % 100 == 0:\n",
    "                print ('Epoch '+  str(epoch) + ' '+ str(sub_epoch)+'/' + str(len(training_data_tag_list)) + '  Loss : ' + str(loss))\n",
    "            '''\n",
    "        print ('Epoch ' + str(epoch) + ' Loss : ' + str (total_loss))\n",
    "        torch.save(model_v1, '../pickle/model_v1.pt')\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss : 15.12510621547699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Bi_GRU_Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss : 14.442784428596497\n",
      "Epoch 2 Loss : 13.761734426021576\n",
      "Epoch 3 Loss : 13.033600449562073\n",
      "Epoch 4 Loss : 12.225331544876099\n",
      "Epoch 5 Loss : 11.320636063814163\n",
      "Epoch 6 Loss : 10.324897915124893\n",
      "Epoch 7 Loss : 9.267999976873398\n",
      "Epoch 8 Loss : 8.198874711990356\n",
      "Epoch 9 Loss : 7.170851528644562\n",
      "Epoch 10 Loss : 6.22552365064621\n",
      "Epoch 11 Loss : 5.384606748819351\n",
      "Epoch 12 Loss : 4.65191262960434\n",
      "Epoch 13 Loss : 4.020511031150818\n",
      "Epoch 14 Loss : 3.479481816291809\n",
      "Epoch 15 Loss : 3.0177440345287323\n",
      "Epoch 16 Loss : 2.6252336502075195\n",
      "Epoch 17 Loss : 2.2928282618522644\n",
      "Epoch 18 Loss : 2.012095034122467\n",
      "Epoch 19 Loss : 1.7752603888511658\n",
      "Epoch 20 Loss : 1.575318992137909\n",
      "Epoch 21 Loss : 1.4061315655708313\n",
      "Epoch 22 Loss : 1.2624595165252686\n",
      "Epoch 23 Loss : 1.1399115324020386\n",
      "Epoch 24 Loss : 1.034857988357544\n",
      "Epoch 25 Loss : 0.944320559501648\n",
      "Epoch 26 Loss : 0.8658663034439087\n",
      "Epoch 27 Loss : 0.7975102663040161\n",
      "Epoch 28 Loss : 0.7376328706741333\n",
      "Epoch 29 Loss : 0.6849079132080078\n",
      "Epoch 30 Loss : 0.6382476091384888\n",
      "Epoch 31 Loss : 0.5967572927474976\n",
      "Epoch 32 Loss : 0.5596939325332642\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cce591515e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-6050fac5109c>\u001b[0m in \u001b[0;36mtrain_v1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             '''\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    model_v1 = Bi_GRU_Model(total_tag=input_size_v1, \n",
    "                            embeding_size = embedding_size_v1,\n",
    "                            gru_hidden=gru_hidden_size_v1,\n",
    "                            output_size=output_size_v1,\n",
    "                            gru_layer = gru_layer_v1)\n",
    "    model_v1 = torch.load('../pickle/model_v1.pt')\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    for seq_tag_idx in range(len(training_data_tag_list)):\n",
    "        \n",
    "        input_data = torch.LongTensor([dict_tag2idx[t] for t in training_data_tag_list[seq_tag_idx]])\n",
    "        target_data = torch.LongTensor([training_target_sentence_list[seq_tag_idx]])\n",
    "        out = model_v1(input_data)\n",
    "        out = out.squeeze(0)\n",
    "        if out[0].item() > out[1].item() and target_data[0].item() == 0:\n",
    "            correct += 1\n",
    "        elif out[0].item() < out[1].item() and target_data[0].item() == 1:\n",
    "            correct += 1\n",
    "        else : \n",
    "            continue\n",
    "    print (correct / len (training_data_tag_list))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
