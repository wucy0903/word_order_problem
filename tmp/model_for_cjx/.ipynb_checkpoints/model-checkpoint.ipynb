{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the using package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the jieba tags\n",
    "* load the \"jieba_tag.csv\"\n",
    "* let each tag fill in the dictionary with the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'ad': 1, 'ag': 2, 'an': 3, 'b': 4, 'c': 5, 'd': 6, 'df': 7, 'dg': 8, 'e': 9, 'f': 10, 'g': 11, 'h': 12, 'i': 13, 'j': 14, 'k': 15, 'l': 16, 'm': 17, 'mg': 18, 'mq': 19, 'n': 20, 'ng': 21, 'nr': 22, 'nrfg': 23, 'nrt': 24, 'ns': 25, 'nz': 26, 'o': 27, 'p': 28, 'q': 29, 'r': 30, 'rg': 31, 'rr': 32, 'rz': 33, 's': 34, 't': 35, 'tg': 36, 'u': 37, 'ud': 38, 'ug': 39, 'uj': 40, 'ul': 41, 'uv': 42, 'uz': 43, 'v': 44, 'vd': 45, 'vg': 46, 'vi': 47, 'vn': 48, 'vq': 49, 'x': 50, 'y': 51, 'z': 52, 'zg': 53}\n"
     ]
    }
   ],
   "source": [
    "jieba_tag_dict = dict()\n",
    "cnt = 0\n",
    "with open ('./jieba_tag.txt' , 'r' , encoding = 'utf-8') as f :\n",
    "    for tag in f.readlines():\n",
    "        jieba_tag_dict[tag.strip('\\n')] = cnt\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture of the Designed Model\n",
    "\n",
    " <img src=\"https://i.imgur.com/JuOTx1S.png\" width = \"300\" height = \"200\" alt=\"design_model\" align=center />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model\n",
    "---\n",
    "#### Pytorch的Embedding:\n",
    "* 常設定參數：\n",
    "    * num_embeddings  : 字典的大小\n",
    "    * embedding_dim : 詞向量維度\n",
    "    \n",
    "* 輸入向量格式：(＊)  <br>\n",
    "* 輸出向量格式 : (＊ , H) <br>\n",
    "＊ : 長整數向量 , e.g. [40] 也就是該詞的index<br>\n",
    " H : 詞向量維度<br>\n",
    " \n",
    "---\n",
    "\n",
    "#### Pytorch的GRU:\n",
    "* 常設定參數：\n",
    "    * input_size  : 輸入向量的維度\n",
    "    * hidden_size : 隱藏層維度\n",
    "    * num_layers : 層數\n",
    "    * bidirectional : 是否雙向\n",
    "    \n",
    "* 輸入向量格式：(L , N , M)  <br>\n",
    "* 輸出向量格式 : (L , N , H) <br>\n",
    "\n",
    "L : 輸入的長度（Sequential length）<br>\n",
    "N : batch size\n",
    "M : input size\n",
    "H : hidden size\n",
    "\n",
    "---\n",
    "#### Pytorch的Conv1d:\n",
    "   * 常設定參數：\n",
    "        * in_channels : 輸入資料的維度\n",
    "        * out_channels : filter的數量\n",
    "        * kernal_size : filter的size\n",
    "   * 輸入向量格式：(N , Cin , L)\n",
    "   * 輸出向量格式 : (N , Cout , Lout)\n",
    "   \n",
    "N : batch size 。<br>\n",
    "Cin : 資料的維度數<br>\n",
    "Cout : filter數量<br>\n",
    "L : 輸入的長度（Sequential length）<br>\n",
    "Lout : 輸出的長度 (會根據filter size和stride的不同而有所不同)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CJX_detect_model (nn.Module):\n",
    "    def __init__(self, total_tag, embeding_size, gru_hidden,gru_layer, filter_num_1, filter_size_1, filter_num_2, filter_size_2 , max_word):\n",
    "        super(CJX_detect_model, self).__init__()\n",
    "        self.total_tag = total_tag\n",
    "        self.max_word = max_word\n",
    "        self.embeding_size = embeding_size\n",
    "        self.gru_hidden = gru_hidden\n",
    "        self.gru_layer = gru_layer\n",
    "        self.filter_num_1 = filter_num_1\n",
    "        self.filter_size_1 = filter_size_1\n",
    "        self.filter_num_2 = filter_num_2\n",
    "        self.filter_size_2 = filter_size_2\n",
    "        self.Embeding = nn.Embedding(self.total_tag, self.embeding_size)\n",
    "        self.GRU = nn.GRU(self.embeding_size , self.gru_hidden, self.gru_layer)\n",
    "        self.Conv1d_layer1 = nn.Sequential(nn.Conv1d(in_channels=self.gru_hidden, \n",
    "                                                            out_channels=self.filter_num_1,\n",
    "                                                            kernel_size=self.filter_size_1),\n",
    "                                                         #nn.BatchNorm1d (self.filter_size_1),\n",
    "                                                         nn.ReLU())\n",
    "        \n",
    "        self.Conv1d_layer2 = nn.Sequential(nn.Conv1d(in_channels=self.filter_num_1, \n",
    "                                                            out_channels=self.filter_num_2,\n",
    "                                                            kernel_size=self.filter_size_2),\n",
    "                                                         #nn.BatchNorm1d (self.filter_size_2),\n",
    "                                                         nn.ReLU())\n",
    "        # batch size is  set to 1 , output_size is set to 2\n",
    "        self.linear = nn.Linear( self.filter_num_2 * self.max_word, 2 )\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        embed_res = self.Embeding (input_data)\n",
    "        print (' Embedding :::: ' , embed_res)\n",
    "        # let the input dimension be the (L , N , M) and the get the output with the dimension (L , N , H)\n",
    "        gru_res, _ = self.GRU(embed_res.unsqueeze(1))\n",
    "        print (' GRU :::: ' , gru_res)\n",
    "        # let the input dimension be the (N , Cin , L) and then the output with the dimension (N, Cout , Lout)\n",
    "        conv_res1 = self.Conv1d_layer1 (gru_res.permute(1, 2,0))\n",
    "        print (' conv_res1 :::: ' , conv_res1)\n",
    "        conv_res2 = self.Conv1d_layer2 (conv_res1)\n",
    "        print ('conv_res2 :::: ' , conv_res2)\n",
    "        linear_res = self.linear(conv_res2.view(-1))\n",
    "        final_res = F.softmax(linear_res)\n",
    "        return final_res\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embedding ::::  tensor([[ 0.1506,  1.5208,  2.9761,  1.1838,  0.0987, -0.3903, -0.5032, -1.1677],\n",
      "        [ 0.4280,  0.9667, -0.0588, -0.4951,  1.1395, -1.5694, -1.3389,  1.3286],\n",
      "        [ 0.9759, -0.9283,  0.5695, -1.5420,  0.3016, -1.5275,  0.8259,  0.3429],\n",
      "        [ 1.0404,  0.2763,  0.9675, -0.7816,  1.6501,  1.3152, -0.3543, -1.3908],\n",
      "        [ 0.3975,  0.3744,  0.1933,  0.6922,  1.1308, -0.3289,  0.5999,  1.1938],\n",
      "        [-0.0718,  0.2411, -0.7474,  1.1049, -0.4046, -1.2706,  0.4334, -1.2556],\n",
      "        [-0.4570, -0.0203,  0.8776, -0.2278,  0.0944,  1.3318, -0.2650,  0.2700]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      " GRU ::::  tensor([[[ 0.2578,  0.8030, -0.2807, -0.0901, -0.4399,  0.1763]],\n",
      "\n",
      "        [[-0.2348, -0.1442, -0.2543,  0.0012, -0.6125, -0.2184]],\n",
      "\n",
      "        [[-0.3359, -0.2513, -0.4482,  0.0106, -0.4497, -0.2885]],\n",
      "\n",
      "        [[-0.3152,  0.3878, -0.0255, -0.0330, -0.1539,  0.0030]],\n",
      "\n",
      "        [[ 0.2376, -0.2366, -0.1585, -0.0613,  0.0929, -0.3179]],\n",
      "\n",
      "        [[ 0.0717,  0.1311,  0.0056,  0.3320, -0.0695, -0.5903]],\n",
      "\n",
      "        [[ 0.1869,  0.2587, -0.1460,  0.0893, -0.2367, -0.1643]]],\n",
      "       grad_fn=<StackBackward>)\n",
      " conv_res1 ::::  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1609, 0.1346, 0.0000, 0.1838, 0.0570],\n",
      "         [0.0358, 0.0000, 0.0000, 0.0991, 0.0481, 0.0000],\n",
      "         [0.4253, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       grad_fn=<ThresholdBackward0>)\n",
      "conv_res2 ::::  tensor([[[0.0405, 0.1716, 0.1993, 0.1790, 0.1792],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2553, 0.1234, 0.1830, 0.1418, 0.1457],\n",
      "         [0.0000, 0.0371, 0.0167, 0.0287, 0.0036],\n",
      "         [0.1312, 0.1280, 0.0872, 0.1268, 0.1093]]],\n",
      "       grad_fn=<ThresholdBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 25], m2: [10 x 2] at /Users/soumith/b101_2/2019_02_08/wheel_build_dirs/wheel_3.6/pytorch/aten/src/TH/generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-0691d45d8c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCJX_detect_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_tag\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_hidden\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mgru_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_num_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_size_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_num_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_size_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-b201bd4b9b0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mconv_res2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d_layer2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv_res1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'conv_res2 :::: '\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mconv_res2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlinear_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_res2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mfinal_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 25], m2: [10 x 2] at /Users/soumith/b101_2/2019_02_08/wheel_build_dirs/wheel_3.6/pytorch/aten/src/TH/generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "# Testing the code\n",
    "model = CJX_detect_model(total_tag= 16, embeding_size=8, gru_hidden= 6 , gru_layer=1, filter_num_1=5, filter_size_1=2, filter_num_2 = 5, filter_size_2 = 2, max_word = 10)\n",
    "test_vec = torch.LongTensor([1,2,3,4,5,6,7])\n",
    "model (test_vec)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.is_training = True\n",
    "        self.dropout_rate = config.dropout_rate\n",
    "        self.num_class = config.num_class\n",
    "        self.use_element = config.use_element\n",
    "        self.config = config\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=config.vocab_size, \n",
    "                                embedding_dim=config.embedding_size)\n",
    "        self.convs = nn.ModuleList([\n",
    "                nn.Sequential(nn.Conv1d(in_channels=config.embedding_size, \n",
    "                                        out_channels=config.feature_size, \n",
    "                                        kernel_size=h),\n",
    "#                              nn.BatchNorm1d(num_features=config.feature_size), \n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool1d(kernel_size=config.max_text_len-h+1))\n",
    "                     for h in config.window_sizes\n",
    "                    ])\n",
    "        self.fc = nn.Linear(in_features=config.feature_size*len(config.window_sizes),\n",
    "                            out_features=config.num_class)\n",
    "        if os.path.exists(config.embedding_path) and config.is_training and config.is_pretrain:\n",
    "            print(\"Loading pretrain embedding...\")\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(np.load(config.embedding_path)))    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        embed_x = self.embedding(x)\n",
    "        \n",
    "        #print('embed size 1',embed_x.size())  # 32*35*256\n",
    "# batch_size x text_len x embedding_size  -> batch_size x embedding_size x text_len\n",
    "        embed_x = embed_x.permute(0, 2, 1)\n",
    "        #print('embed size 2',embed_x.size())  # 32*256*35\n",
    "        out = [conv(embed_x) for conv in self.convs]  #out[i]:batch_size x feature_size*1\n",
    "        #for o in out:\n",
    "        #    print('o',o.size())  # 32*100*1\n",
    "        out = torch.cat(out, dim=1)  # 對應第二個維度（行）拼接起來，比如說5*2*1,5*3*1的拼接變成5*5*1\n",
    "        #print(out.size(1)) # 32*400*1\n",
    "        out = out.view(-1, out.size(1)) \n",
    "        #print(out.size())  # 32*400 \n",
    "        if not self.use_element:\n",
    "            out = F.dropout(input=out, p=self.dropout_rate)\n",
    "            out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [2., 3., 4.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "b = torch.Tensor([[2,3,4]])\n",
    "torch.cat((a,b),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
