{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the using package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the jieba tags\n",
    "* load the \"jieba_tag.csv\"\n",
    "* let each tag fill in the dictionary with the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba_tag_dict = dict()\n",
    "cnt = 0\n",
    "with open ('./jieba_tag.txt' , 'r' , encoding = 'utf-8') as f :\n",
    "    for tag in f.readlines():\n",
    "        jieba_tag_dict[tag.strip('\\n')] = cnt\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture of the Designed Model using GRU and Convolution 1D\n",
    "\n",
    " <img src=\"https://i.imgur.com/JuOTx1S.png\" width = \"300\" height = \"200\" alt=\"design_model\" align=center />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model\n",
    "---\n",
    "#### Pytorch的Embedding:\n",
    "* 常設定參數：\n",
    "    * num_embeddings  : 字典的大小\n",
    "    * embedding_dim : 詞向量維度\n",
    "    \n",
    "* 輸入向量格式：(＊)  <br>\n",
    "* 輸出向量格式 : (＊ , H) <br>\n",
    "＊ : 長整數向量 , e.g. [40] 也就是該詞的index<br>\n",
    " H : 詞向量維度<br>\n",
    " \n",
    "---\n",
    "\n",
    "#### Pytorch的GRU:\n",
    "* 常設定參數：\n",
    "    * input_size  : 輸入向量的維度\n",
    "    * hidden_size : 隱藏層維度\n",
    "    * num_layers : 層數\n",
    "    * bidirectional : 是否雙向\n",
    "    \n",
    "* 輸入向量格式：(L , N , M)  <br>\n",
    "* 輸出向量格式 : (L , N , H) <br>\n",
    "\n",
    "L : 輸入的長度（Sequential length）<br>\n",
    "N : batch size\n",
    "M : input size\n",
    "H : hidden size\n",
    "\n",
    "---\n",
    "#### Pytorch的Conv1d:\n",
    "   * 常設定參數：\n",
    "        * in_channels : 輸入資料的維度\n",
    "        * out_channels : filter的數量\n",
    "        * kernal_size : filter的size\n",
    "   * 輸入向量格式：(N , Cin , L)\n",
    "   * 輸出向量格式 : (N , Cout , Lout)\n",
    "   \n",
    "N : batch size 。<br>\n",
    "Cin : 資料的維度數<br>\n",
    "Cout : filter數量<br>\n",
    "L : 輸入的長度（Sequential length）<br>\n",
    "Lout : 輸出的長度 (會根據filter size和stride的不同而有所不同)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_with_Conv1D_Model (nn.Module):\n",
    "    def __init__(self, total_tag, embeding_size, gru_hidden,gru_layer, filter_num_1, filter_size_1, filter_num_2, filter_size_2, output_size, max_word):\n",
    "        super(GRU_with_Conv1D_Model, self).__init__()\n",
    "        self.total_tag = total_tag\n",
    "        self.max_word = max_word\n",
    "        self.embeding_size = embeding_size\n",
    "        self.gru_hidden = gru_hidden\n",
    "        self.gru_layer = gru_layer\n",
    "        self.filter_num_1 = filter_num_1\n",
    "        self.filter_size_1 = filter_size_1\n",
    "        self.filter_num_2 = filter_num_2\n",
    "        self.filter_size_2 = filter_size_2\n",
    "        self.output_size = output_size\n",
    "        self.Embeding = nn.Embedding(self.total_tag, self.embeding_size)\n",
    "        self.GRU = nn.GRU(self.embeding_size , self.gru_hidden, self.gru_layer, bidirectional = True)\n",
    "        self.Conv1d_layer1 = nn.Sequential(nn.Conv1d(in_channels=self.gru_hidden*2, \n",
    "                                                            out_channels=self.filter_num_1,\n",
    "                                                            kernel_size=self.filter_size_1),\n",
    "                                                         #nn.BatchNorm1d (self.filter_size_1),\n",
    "                                                         nn.ReLU())\n",
    "        \n",
    "        self.Conv1d_layer2 = nn.Sequential(nn.Conv1d(in_channels=self.filter_num_1, \n",
    "                                                            out_channels=self.filter_num_2,\n",
    "                                                            kernel_size=self.filter_size_2),\n",
    "                                                         #nn.BatchNorm1d (self.filter_size_2),\n",
    "                                                         nn.ReLU())\n",
    "        # batch size is  set to 1 , output_size is set to 2\n",
    "        L = (self.max_word- self.filter_size_1+ 1)- self.filter_size_2+ 1\n",
    "        self.linear = nn.Linear( self.filter_num_2 * L, self.output_size)\n",
    "        \n",
    "    def forward(self, input_data):  \n",
    "        embed_res = self.Embeding (input_data)\n",
    "        if len(input_data) < self.max_word:\n",
    "            for c in range (self.max_word - len(input_data)):\n",
    "                embed_res = torch.cat((embed_res, torch.zeros(1, self.embeding_size)),dim = 0 )\n",
    "        print (' Embedding :::: ' , embed_res.size())\n",
    "        # let the input dimension be the (L , N , M) and the get the output with the dimension (L , N , H)\n",
    "        gru_res, _ = self.GRU(embed_res.unsqueeze(1))\n",
    "        print (' GRU :::: ' , gru_res.size())\n",
    "        # let the input dimension be the (N , Cin , L) and then the output with the dimension (N, Cout , Lout)\n",
    "        conv_res1 = self.Conv1d_layer1 (gru_res.permute(1,2,0))\n",
    "        print (' conv_res1 :::: ' , conv_res1.size())\n",
    "        conv_res2 = self.Conv1d_layer2 (conv_res1)\n",
    "        print ('conv_res2 :::: ' , conv_res2.size())\n",
    "        linear_res = self.linear(conv_res2.view(-1))\n",
    "        final_res = F.sigmoid(linear_res)\n",
    "        return final_res\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embedding ::::  torch.Size([10, 8])\n",
      " GRU ::::  torch.Size([10, 1, 12])\n",
      " conv_res1 ::::  torch.Size([1, 5, 9])\n",
      "conv_res2 ::::  torch.Size([1, 5, 8])\n",
      "V3_Model_with_conv_and_gru ::: \n",
      " GRU_with_Conv1D_Model(\n",
      "  (Embeding): Embedding(16, 8)\n",
      "  (GRU): GRU(8, 6, bidirectional=True)\n",
      "  (Conv1d_layer1): Sequential(\n",
      "    (0): Conv1d(12, 5, kernel_size=(2,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (Conv1d_layer2): Sequential(\n",
      "    (0): Conv1d(5, 5, kernel_size=(2,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (linear): Linear(in_features=40, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "# Testing the code\n",
    "model_v3 = GRU_with_Conv1D_Model(total_tag= 16, embeding_size=8, gru_hidden= 6 , gru_layer=1, filter_num_1=5, filter_size_1=2, filter_num_2 = 5, filter_size_2 = 2,output_size = 7, max_word = 10)\n",
    "test_vec = torch.LongTensor([1,2,3,4,5,6,7])\n",
    "model_v3 (test_vec)\n",
    "print ('V3_Model_with_conv_and_gru ::: \\n', model_v3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture of the Designed Model using only Bi-GRU \n",
    "<img src=\"https://i.imgur.com/wOizgXZ.png\" width = \"300\" height = \"200\" alt=\"design_model\" align=center />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bi_GRU_Model (nn.Module):\n",
    "    def __init__(self, total_tag, embeding_size, gru_hidden,gru_layer, output_size):\n",
    "        super(Bi_GRU_Model, self).__init__()\n",
    "        self.total_tag = total_tag\n",
    "        self.embeding_size = embeding_size\n",
    "        self.gru_hidden = gru_hidden\n",
    "        self.gru_layer = gru_layer\n",
    "        self.output_size = output_size\n",
    "        self.Embeding = nn.Embedding(self.total_tag, self.embeding_size)\n",
    "        self.GRU = nn.GRU(self.embeding_size , self.gru_hidden, self.gru_layer, bidirectional= True)\n",
    "        \n",
    "        # batch size is  set to 1 , output_size is set to 2\n",
    "        self.linear = nn.Linear( self.gru_hidden*2 , self.output_size )\n",
    "        \n",
    "    def forward(self, input_data):  \n",
    "        embed_res = self.Embeding (input_data)\n",
    "        print ('Embedding :::: ' , embed_res.size())\n",
    "        # let the input dimension be the (L , N , M) and the get the output with the dimension (L , N , H)\n",
    "        gru_res, _ = self.GRU(embed_res.unsqueeze(1))\n",
    "        print (\"GRU :::: \", gru_res.size())\n",
    "        linear_res = self.linear(gru_res[-1])\n",
    "        final_res = F.sigmoid(linear_res)\n",
    "        print ('final res :::: ' , final_res)\n",
    "        return final_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding ::::  torch.Size([7, 8])\n",
      "GRU ::::  torch.Size([7, 1, 12])\n",
      "final res ::::  tensor([[0.3744, 0.5347, 0.4801, 0.5206, 0.5743, 0.5495, 0.5178]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "V1_Model_with_only_gru ::: \n",
      " Bi_GRU_Model(\n",
      "  (Embeding): Embedding(16, 8)\n",
      "  (GRU): GRU(8, 6, bidirectional=True)\n",
      "  (linear): Linear(in_features=12, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "model_v1 = Bi_GRU_Model(total_tag=16, embeding_size=8, gru_hidden= 6 , gru_layer=1, output_size=7 )\n",
    "test_vec = torch.LongTensor([1,2,3,4,5,6,7])\n",
    "model_v1(test_vec)\n",
    "print ('V1_Model_with_only_gru ::: \\n', model_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture of the Designed Model using only Bi-GRU \n",
    "<img src=\"https://i.imgur.com/zjsZb0l.png\" width = \"300\" height = \"200\" alt=\"design_model\" align=center />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution_1D_Model (nn.Module):\n",
    "    def __init__(self, total_tag, embeding_size, filter_num_1, filter_size_1, filter_num_2, filter_size_2 , output_size,max_word):\n",
    "        super(Convolution_1D_Model, self).__init__()\n",
    "        self.total_tag = total_tag\n",
    "        self.max_word = max_word\n",
    "        self.embeding_size = embeding_size\n",
    "        self.filter_num_1 = filter_num_1\n",
    "        self.filter_size_1 = filter_size_1\n",
    "        self.filter_num_2 = filter_num_2\n",
    "        self.filter_size_2 = filter_size_2\n",
    "        self.output_size = output_size\n",
    "        self.Embeding = nn.Embedding(self.total_tag, self.embeding_size)\n",
    "        self.Conv1d_layer1 = nn.Sequential(nn.Conv1d(in_channels=self.embeding_size, \n",
    "                                                            out_channels=self.filter_num_1,\n",
    "                                                            kernel_size=self.filter_size_1),\n",
    "                                                         #nn.BatchNorm1d (self.filter_size_1),\n",
    "                                                         nn.ReLU())\n",
    "        \n",
    "        self.Conv1d_layer2 = nn.Sequential(nn.Conv1d(in_channels=self.filter_num_1, \n",
    "                                                            out_channels=self.filter_num_2,\n",
    "                                                            kernel_size=self.filter_size_2),\n",
    "                                                         #nn.BatchNorm1d (self.filter_size_2),\n",
    "                                                         nn.ReLU())\n",
    "        # batch size is  set to 1 , output_size is set to 2\n",
    "        L = (self.max_word- self.filter_size_1+ 1)- self.filter_size_2+ 1\n",
    "        self.linear = nn.Linear( self.filter_num_2 * L, self.output_size )\n",
    "        \n",
    "    def forward(self, input_data):  \n",
    "        embed_res = self.Embeding (input_data)\n",
    "        if len(input_data) < self.max_word:\n",
    "            for c in range (self.max_word - len(input_data)):\n",
    "                embed_res = torch.cat((embed_res, torch.zeros(1, self.embeding_size)),dim = 0 )\n",
    "        embed_res = embed_res.unsqueeze(0)\n",
    "        print (' Embedding :::: ' , embed_res.size())\n",
    "        # let the input dimension be the (N , Cin , L) and then the output with the dimension (N, Cout , Lout)\n",
    "        conv_res1 = self.Conv1d_layer1 (embed_res.permute(0,2,1))\n",
    "        print (' conv_res1 :::: ' , conv_res1.size())\n",
    "        conv_res2 = self.Conv1d_layer2 (conv_res1)\n",
    "        print ('conv_res2 :::: ' , conv_res2.size())\n",
    "        linear_res = self.linear(conv_res2.view(-1))\n",
    "        final_res = F.sigmoid(linear_res)\n",
    "        print (\"final_res :::: \" , final_res)\n",
    "        return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embedding ::::  torch.Size([1, 10, 8])\n",
      " conv_res1 ::::  torch.Size([1, 5, 9])\n",
      "conv_res2 ::::  torch.Size([1, 5, 8])\n",
      "final_res ::::  tensor([0.5161, 0.4780, 0.5138, 0.5408, 0.5429, 0.4728, 0.5267],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "V2_Model_with_only_convolution1D ::: \n",
      " Convolution_1D_Model(\n",
      "  (Embeding): Embedding(16, 8)\n",
      "  (Conv1d_layer1): Sequential(\n",
      "    (0): Conv1d(8, 5, kernel_size=(2,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (Conv1d_layer2): Sequential(\n",
      "    (0): Conv1d(5, 5, kernel_size=(2,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (linear): Linear(in_features=40, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "model_v2 = Convolution_1D_Model(total_tag=16, embeding_size=8, filter_num_1=5, filter_size_1=2, filter_num_2=5, filter_size_2=2 ,output_size = 7, max_word=10)\n",
    "test_vec = torch.LongTensor([1,2,3,4,5,6,7])\n",
    "model_v2(test_vec)\n",
    "print ('V2_Model_with_only_convolution1D ::: \\n', model_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_v1 ():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
